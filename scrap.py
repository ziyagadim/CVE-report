from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.common.exceptions import NoSuchElementException 
import requests
from requests import ConnectionError

import time

op = webdriver.ChromeOptions()
op.add_argument('headless')
op.add_argument('--log-level=3')
driver = webdriver.Chrome(options=op)


def check_link(list):
    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}
    
    ##TODO add function if that link contains info we need
     

    exist_links = []
    for link in list:
        try:
            if requests.get(link, headers=headers).status_code == 200:
                exist_links.append(link)
        except ConnectionError:
            pass

    return exist_links        


def nist(cve_id):
    driver.get(f'https://nvd.nist.gov/vuln/detail/{cve_id}')

    # references
    references = driver.find_elements(By.XPATH, '//*[@id="vulnHyperlinksPanel"]/table/tbody')

    # editing list 
    ref_list = [elm.text for elm in references]
    ref_list = ref_list[0].split('\n')
    links = [i.split(' ')[0] for i in ref_list]

    link = check_link(links)

    if link == []:
        link = 'There is info to display'

    # Checks Cvss3 if not exist returns cvss2
    try:
        if bool(driver.find_element(By.ID, 'Cvss3NistCalculatorAnchor')):
            severity = driver.find_element(By.ID, 'Cvss3NistCalculatorAnchor').text
            vector = driver.find_element(By.XPATH, '//*[@id="Vuln3CvssPanel"]/div[1]/div[3]/span/span').text
    except NoSuchElementException:
        if bool(driver.find_element(By.ID, 'Cvss3NistCalculatorAnchorNA')):
            driver.find_element(By.ID, 'btn-cvss2').click()
            severity = driver.find_element(By.ID, 'Cvss2CalculatorAnchor').text
            vector = driver.find_element(By.XPATH, '//*[@id="Vuln2CvssPanel"]/div[1]/div[3]/span/span').text

    # Description handling
    try:
        description = driver.find_element(By.XPATH, '//*[@id="vulnDetailTableView"]/tbody/tr/td/div/div[1]/p').text
    except NoSuchElementException:
        print("Something went wrong with CVE ID you provided!!! Please contact with developers!")

    return {'description': description, 'severity': severity, 'vector': vector, 'reference': link}


def mitre(cve_id):
    driver.get(f'https://cve.mitre.org/cgi-bin/cvename.cgi?name={cve_id}')

    description = driver.find_element(By.XPATH, '//*[@id="GeneratedTable"]/table/tbody/tr[4]/td').text

#######################################
    links = driver.find_elements(By.XPATH, '//*[@id="GeneratedTable"]/table/tbody/tr[7]/td/ul')

    list = [i.text for i in links]
    list = list[0].split('\n')

    # delete unwanted items 
    url = []
    for item in list:
        parts = item.split(':')  # Split item by ':'
        if len(parts) > 1 and parts[1].startswith('http'):  # Check if the second part starts with 'http'
            link = ':'.join(parts[1:])  # Join the remaining parts back together
            url.append(link.strip())  # Add the URL to the urls list after stripping any leading/trailing whitespace
    # url list contains actual references links
    
    url = check_link(url)

    #TODO add condition if list is empty

    if url == []:
        url = 'There is no information to display'


#######################################
    
    # Assingning CNA
    try:
        assigning_CNA = driver.find_element(By.XPATH, '//*[@id="GeneratedTable"]/table/tbody/tr[9]/td').text
    except NoSuchElementException:
        assigning_CNA = 'There is no information to display'

    # record create date
    try:
        date = driver.find_element(By.XPATH, '//*[@id="GeneratedTable"]/table/tbody/tr[11]/td[1]/b').text
    except NoSuchElementException:
        date = 'There is no information to display'

    # Comment
    try:
        comment = driver.find_element(By.XPATH, '//*[@id="GeneratedTable"]/table/tbody/tr[17]/td').text
    except NoSuchElementException:
        comment = 'There is no information to display'

    return {'description': description, 'references': url ,'assigning_CNA': assigning_CNA, 'date': date, 'comment': comment}


def vulners(cve_id):
    driver.get(f'https://vulners.com/cve/{cve_id}')

    description = driver.find_element(By.XPATH, '//*[@id="body"]/div[1]/div[2]/div[2]/div/div[1]/div[1]/div[4]/div/p').text
    cvvs  = driver.find_element(By.XPATH, '//*[@id="body"]/div[1]/div[2]/div[2]/div/div[1]/div[1]/div[3]/div[1]/div/div[1]/div/p').text

    ##############################
    references = driver.find_element(By.XPATH, '//*[@id="body"]/div[1]/div[2]/div[2]/div/div[1]/div[1]/div[6]').find_elements(By.TAG_NAME, 'a')

    list = [i.get_attribute('href') for i in references]
    list = check_link(list)
    if list == []:
        list = 'There is no source to display!'
    
    
    ##############################


    return {'cvvs': cvvs, 'description': description, 'references': list}

# Vulmon doesnt work in some cases!
def vulmon(cve_id):
    driver.get(f'https://vulmon.com/vulnerabilitydetails?qid={cve_id}')

    # Get cvss
    try:
        cvss = driver.find_element(By.CLASS_NAME, 'value').text
    except NoSuchElementException:
        cvss = 'There is no info to display'
    
    # Get vector
    try:
        vector = driver.find_element(By.XPATH, '//*[@id="cust-css-overrides"]/div[3]/div/div[1]/div[1]/div/div/div/div[7]').text.split(' ')[1]
    except NoSuchElementException:
        vector = 'There is no info to display'

    # Get summary
    try:    
        summary = driver.find_element(By.XPATH, '//*[@id="cust-css-overrides"]/div[3]/div/div[1]/div[2]/p').text
    except NoSuchElementException:
        summary = 'There is no info to display'

   # Finds exploit links and adds into list
    
    try:
        exploits_div = driver.find_element(By.XPATH,'//*[@id="cust-css-overrides"]/div[3]/div/div[1]/div[5]/div').find_elements(By.TAG_NAME, 'a')
        exploits = []
        for i in exploits_div:
            exploits.append(i.get_attribute('href'))
        exploits = check_link(exploits)

        if exploits == []:
            exploits = 'There is no info to display'
    except NoSuchElementException:
        exploits = 'There is no info to display'

    # Finds github links and adds into list
    try:    
        github_div = driver.find_element(By.XPATH, '//*[@id="cust-css-overrides"]/div[3]/div/div[1]/div[6]').find_elements(By.TAG_NAME, 'a')
        github_links = []
        for i in github_div:
            github_links.append(i.get_attribute('href'))
        github_links = check_link(github_links)

        if github_links == []:
            github_links = 'There is no info to display'
    except NoSuchElementException:
        github_links = 'There is no info to display'

    # Finds source links and adds into list
    try:
        source_div = driver.find_element(By.XPATH, '//*[@id="cust-css-overrides"]/div[3]/div/div[1]/div[8]').find_elements(By.TAG_NAME, 'a')
        source_links = []
        for i in source_div:
            source_links.append(i.get_attribute('href'))
        source_links = check_link(source_links)

        if source_links == []:
            source_links = 'There is no info to display'
    except NoSuchElementException:
        source_links = 'There is no info to display'


    # print(cvss)
    # print(20*'=')
    # print(vector)
    # print(20*'=')
    # print(summary)
    # print(20*'=')
    # print(exploits)
    # print(20*'=')
    # print(github_links)
    # print(20*'=')
    # print(source_links)


def get_exploit(cve_id):
    try:
        driver.get(f'https://www.exploit-db.com/search?cve={cve_id}')

        time.sleep(3)

        table = driver.find_element(By.XPATH, '//*[@id="exploits-table"]').find_elements(By.TAG_NAME, 'a')
        
        all_links = []
        for i in table:
            all_links.append(i.get_attribute('href'))
        
        dowload_links = all_links[::2]
        exploit_links = all_links[1::2]

        time.sleep(3)



    except NoSuchElementException:
        print("no such element")

    
    return {'download_link':dowload_links, 'exploit_link':exploit_links}
